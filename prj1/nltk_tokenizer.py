from nltk.tokenize import word_tokenize

sentence =""

word_tokenize(sentence)


